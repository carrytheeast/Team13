{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98883be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import copy\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "FACEMESH_LEFT_EYE = frozenset([(263, 249), (249, 390), (390, 373), (373, 374),\n",
    "                               (374, 380), (380, 381), (381, 382), (382, 362),\n",
    "                               (263, 466), (466, 388), (388, 387), (387, 386),\n",
    "                               (386, 385), (385, 384), (384, 398), (398, 362)])\n",
    "FACEMESH_RIGHT_EYE = frozenset([(33, 7), (7, 163), (163, 144), (144, 145),\n",
    "                                (145, 153), (153, 154), (154, 155), (155, 133),\n",
    "                                (33, 246), (246, 161), (161, 160), (160, 159),\n",
    "                                (159, 158), (158, 157), (157, 173), (173, 133)])\n",
    "FACEMESH_CONTOURS = frozenset().union(*[FACEMESH_LEFT_EYE, FACEMESH_RIGHT_EYE])\n",
    "FACEMESH_RIGHT_IRIS = frozenset([(469, 470), (470, 471), (471, 472),(472, 469)])\n",
    "FACEMESH_LEFT_IRIS = frozenset([(474, 475), (475, 476), (476, 477),(477, 474)])\n",
    "FACEMESH_IRISES = frozenset().union(*[FACEMESH_LEFT_IRIS, FACEMESH_RIGHT_IRIS])\n",
    "FACEMESH_LEFT_EYE = frozenset([(263, 249), (249, 390), (390, 373), (373, 374),\n",
    "                       (374, 380), (380, 381), (381, 382), (382, 362),\n",
    "                       (263, 466), (466, 388), (388, 387), (387, 386),\n",
    "                       (386, 385), (385, 384), (384, 398), (398, 362)])\n",
    "FACEMESH_RIGHT_EYE = frozenset([(33, 7), (7, 163), (163, 144), (144, 145),\n",
    "                                (145, 153), (153, 154), (154, 155), (155, 133),\n",
    "                                (33, 246), (246, 161), (161, 160), (160, 159),\n",
    "                                (159, 158), (158, 157), (157, 173), (173, 133)])\n",
    "FACEMESH_EYES = frozenset().union(*[FACEMESH_LEFT_EYE, FACEMESH_RIGHT_EYE])\n",
    "right_under = [7,33,133,144,145,153,154,155,163]\n",
    "left_under = [249,263,362,373,374,380,381,382,390]\n",
    "under = frozenset().union(right_under,left_under) # under에는 양끝 눈꺼풀도 포함되어 있음\n",
    "# For webcam input:\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "# variable\n",
    "ok_flag = 1\n",
    "total_landmarks=[]\n",
    "dir_r = None\n",
    "dir_l = None\n",
    "dir_ = None    \n",
    "aaaa=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7efee87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "# path, thres, thres_ear 설정\n",
    "\n",
    "path = 'shorts24.mp4'# default: None, * 휴대폰 촬영 영상 -> 이후 코드에서 180도 회전 주석 확인\n",
    "# example video: shorts12: , short16:측정불가, shorts17: 2명이상, shorts26: 안구운동\n",
    "\n",
    "thres = 0.45 # thres < 0.5 (select in 0.40 ~ 0.47)  => e.g. [thres|----|(1-thres)]  \n",
    "thres_ = 1-thres\n",
    "thres_ear = 0.5 # thres_ear >= 0.5\n",
    "\n",
    "if path:\n",
    "    cap = cv2.VideoCapture(path)\n",
    "else:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_face_mesh.FaceMesh( max_num_faces=1, refine_landmarks=True,\n",
    "    min_detection_confidence=0.5, min_tracking_confidence=0.5) as face_mesh:\n",
    "\n",
    "    while cap.isOpened() and ok_flag == 1:\n",
    "        success, image = cap.read()\n",
    "        aaaa+=1 # frame 개수\n",
    "#         image=image[::-1] # 주의, 폰으로 촬영시 180도 뒤집히는 현상\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            continue\n",
    "            \n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(image)\n",
    "        x = image.shape[1] # height\n",
    "        y = image.shape[0] # width\n",
    "\n",
    "        # Draw the face mesh annotations on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in (results.multi_face_landmarks):\n",
    "                # Drawing base line(facemesh)\n",
    "                # eyes\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=image,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=FACEMESH_CONTOURS,\n",
    "                    landmark_drawing_spec=None,\n",
    "                    connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style())\n",
    "                # irises\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=image,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "                    # mp_face_mesh\n",
    "                    landmark_drawing_spec=None,\n",
    "                    connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_iris_connections_style())\n",
    "                total_landmarks.append(face_landmarks.landmark)\n",
    "\n",
    "                # Make DataFrames------------------------------------------------------------\n",
    "                # iris data frame\n",
    "                irises=[] # temporary list\n",
    "                for iris, _ in FACEMESH_IRISES:\n",
    "                    irises.append(iris)\n",
    "                irises.sort() # order\n",
    "                total = [] # to be iris dataframe\n",
    "                for n,_ in enumerate(irises):\n",
    "                    n+=1\n",
    "                    # 좌표 x,y,z값 순서 각 4개씩 (오른쪽눈 < 왼쪽눈) \n",
    "                    if n <=len(FACEMESH_LEFT_IRIS):\n",
    "                        direction = 'right'\n",
    "                    else:\n",
    "                        n-=len(FACEMESH_LEFT_IRIS)\n",
    "                        direction = 'left'\n",
    "                    now = [_,direction ,face_landmarks.landmark[_].x,face_landmarks.landmark[_].y,face_landmarks.landmark[_].z] # info in this time\n",
    "                    total.append(now) \n",
    "                iris_df = pd.DataFrame(total, columns = ['idx','dir','x','y','z']) # idx: landmark, dir: right/left\n",
    "                \n",
    "                # iris / normalized data => resize to origin and to int\n",
    "                iris_df['x'] = iris_df['x']*x\n",
    "                iris_df['y'] = iris_df['y']*y\n",
    "                iris_df['x'] = iris_df['x'].astype('int64')\n",
    "                iris_df['y'] = iris_df['y'].astype('int64')\n",
    "\n",
    "                # eyes data frame\n",
    "                eyes=[] # temporary list\n",
    "                for eye, _ in FACEMESH_EYES:\n",
    "                    eyes.append(eye)\n",
    "                    eyes.append(_)\n",
    "                eyes = list(set(eyes))\n",
    "                eyes.sort() # order\n",
    "                total = [] # to be eyes dataframe\n",
    "                for n,_ in enumerate(eyes):\n",
    "                    n+=1\n",
    "                    # 좌표 x,y,z값 순서 각 16개씩 (오른쪽눈 < 왼쪽눈) \n",
    "                    if n <= len(FACEMESH_LEFT_EYE): \n",
    "                        direction = 'right'     \n",
    "                    else:\n",
    "                        n-=int(len(FACEMESH_LEFT_EYE))\n",
    "                        direction = 'left'\n",
    "                    if _ in under:\n",
    "                        loc = 'under'\n",
    "                    else:\n",
    "                        loc = 'up'\n",
    "                    now = [_,direction ,face_landmarks.landmark[_].x,face_landmarks.landmark[_].y,face_landmarks.landmark[_].z,loc] # info in this time\n",
    "                    total.append(now)\n",
    "                eyes_df = pd.DataFrame(total, columns = ['idx','dir','x','y','z','loc']) # idx: landmark, dir: right/left, loc: up/down\n",
    "                \n",
    "                # eyes / normalized data => resize to origin and to int\n",
    "                eyes_df['x'] = eyes_df['x']*x\n",
    "                eyes_df['y'] = eyes_df['y']*y\n",
    "                eyes_df['x'] = eyes_df['x'].astype('int64')\n",
    "                eyes_df['y'] = eyes_df['y'].astype('int64')\n",
    "                \n",
    "                # Gaze Point Estimation------------------------------------------------------------\n",
    "                # 오른쪽 동공의 각 끝 좌표\n",
    "                n469_x, n469_y = iris_df[iris_df['idx']==469].x,iris_df[iris_df['idx']==469].y\n",
    "                n471_x, n471_y = iris_df[iris_df['idx']==471].x,iris_df[iris_df['idx']==471].y\n",
    "                # 왼쪽 동공의 각 끝 좌표\n",
    "                n474_x, n474_y = iris_df[iris_df['idx']==474].x,iris_df[iris_df['idx']==474].y\n",
    "                n476_x, n476_y = iris_df[iris_df['idx']==476].x,iris_df[iris_df['idx']==476].y\n",
    "                \n",
    "                # 오른쪽 동공의 중심좌표\n",
    "                dot_r = ((int(n469_x) + int(n471_x)) / 2, (int(n469_y) + int(n471_y)) / 2)\n",
    "                # 왼쪽 동공의 중심좌표\n",
    "                dot_l = ((int(n474_x) + int(n476_x)) / 2, (int(n474_y) + int(n476_y)) / 2)\n",
    "\n",
    "                # 오른쪽 눈꺼풀의 각 끝 좌표와 길이\n",
    "                n33 = (eyes_df[eyes_df['idx']==33].x,eyes_df[eyes_df['idx']==33].y)\n",
    "                n133 = (eyes_df[eyes_df['idx']==133].x,eyes_df[eyes_df['idx']==133].y) \n",
    "                dist_r = math.dist(n33,n133)\n",
    "                # 왼쪽 눈꺼풀의 각 끝 좌표와 길이\n",
    "                n263 = (eyes_df[eyes_df['idx']==263].x,eyes_df[eyes_df['idx']==263].y)\n",
    "                n362 = (eyes_df[eyes_df['idx']==362].x,eyes_df[eyes_df['idx']==362].y)\n",
    "                dist_l = math.dist(n263,n362)\n",
    "\n",
    "                # 오른쪽 밑 눈꺼풀\n",
    "                n145 = (eyes_df[eyes_df['idx']==145].x,eyes_df[eyes_df['idx']==145].y)\n",
    "                # 왼쪽 밑 눈꺼풀\n",
    "                n374 = (eyes_df[eyes_df['idx']==374].x,eyes_df[eyes_df['idx']==374].y)\n",
    "                \n",
    "                # 오른쪽 눈 방향 (좌우)\n",
    "                r_ratio = round((math.dist(dot_r, n133)/dist_r),5) # if ratio < thres: left\n",
    "                if r_ratio:\n",
    "                    if r_ratio < thres:\n",
    "                        dir_r = 'Right'\n",
    "                    elif r_ratio > thres_:\n",
    "                        dir_r = 'Left'\n",
    "                    else:\n",
    "                        dir_r = 'Center'\n",
    "                # 왼쪽 눈 방향 (좌우)\n",
    "                l_ratio = round((math.dist(dot_l, n263)/dist_l),5) # if ratio < thres: left                \n",
    "                if l_ratio:\n",
    "                    if l_ratio < thres:\n",
    "                        dir_l = 'Right'\n",
    "                    elif l_ratio > thres_:\n",
    "                        dir_l = 'Left'\n",
    "                    else:\n",
    "                        dir_l = 'Center'\n",
    "                # 통합 눈 방향 (좌우)\n",
    "                if dir_r == dir_l:\n",
    "                    dir_ = dir_r\n",
    "                elif ((dir_r =='Right') and (dir_l =='Left')) or ((dir_r == 'Left') and (dir_l == 'Right')):\n",
    "                    dir_ = 'Center' # 양 끝 값일 때, 중앙으로\n",
    "                else: # [rightcenter, leftcenter, centerright, centerleft]\n",
    "                    dir_ = [dir_r,dir_l]\n",
    "                    if ('Right' in dir_) and ('Center' in dir_):\n",
    "                        dir_ = 'RightCenter'\n",
    "                    if ('Left' in dir_) and ('Center' in dir_):\n",
    "                        dir_ = 'LeftCenter'\n",
    "\n",
    "#                 up_r = iris_df[iris_df['idx']==472]['y'][3] - eyes_df[eyes_df['idx']==145].y[4] # if up<0: up\n",
    "#                 up_l = iris_df[iris_df['idx']==477]['y'][7] - eyes_df[eyes_df['idx']==374].y[20] # if up<0: up\n",
    "\n",
    "                # EAR ratio--------------------------------------------------\n",
    "                # 오른쪽 눈 방향 (상하) : (|161-163|+|157-154|)/2*|133-33|*1/100\n",
    "                n161 = (eyes_df[eyes_df['idx']==161].x,eyes_df[eyes_df['idx']==161].y)\n",
    "                n163 = (eyes_df[eyes_df['idx']==163].x,eyes_df[eyes_df['idx']==163].y)\n",
    "                n154 = (eyes_df[eyes_df['idx']==154].x,eyes_df[eyes_df['idx']==154].y)\n",
    "                n157 = (eyes_df[eyes_df['idx']==157].x,eyes_df[eyes_df['idx']==157].y)\n",
    "                right_ear = (abs(math.dist(n161,n163))+abs(math.dist(n157,n154)))/2*abs(math.dist(n133,n33))/1000\n",
    "                # 왼쪽 눈 방향 (상하) : (|384-381|+|388-390|)/2*|263-362|*1/100\n",
    "                n381 = (eyes_df[eyes_df['idx']==381].x,eyes_df[eyes_df['idx']==381].y)\n",
    "                n384 = (eyes_df[eyes_df['idx']==384].x,eyes_df[eyes_df['idx']==384].y)\n",
    "                n388 = (eyes_df[eyes_df['idx']==388].x,eyes_df[eyes_df['idx']==388].y)\n",
    "                n390 = (eyes_df[eyes_df['idx']==390].x,eyes_df[eyes_df['idx']==390].y)\n",
    "                left_ear = (abs(math.dist(n384,n381))+abs(math.dist(n388,n390)))/2*abs(math.dist(n263,n362))/1000\n",
    "                \n",
    "                # Right iris(468) z vs Left iris(473) z: higher value is closer camera.\n",
    "                if face_landmarks.landmark[468].z > face_landmarks.landmark[473].z:\n",
    "                    using_ear = right_ear\n",
    "                else:\n",
    "                    using_ear = left_ear\n",
    "                if using_ear <= 0.15:\n",
    "                    ear = 'CLOSE'\n",
    "                elif (using_ear > 0.15) and (using_ear <= thres_ear/2):# thres_ear_ = thres_ear/2\n",
    "                    ear = 'DOWN'\n",
    "                elif (using_ear > 0.4) and (using_ear < thres_ear): # thres_ear = 0.5\n",
    "                    ear = 'MIDDLE'\n",
    "                else:\n",
    "                    ear = 'UP'\n",
    "\n",
    "#                 Grid line--------------------------------------------------\n",
    "                range_w = 50 # 좌측부터 2,3번째 그리드의 x좌표 간격에 각각 +,- 값 \n",
    "                cv2.line(image,(n33[0][1]-range_w,0),(n33[0][1]-range_w,y),(255,0,0),3) # n33[0][1]= n33_x\n",
    "                cv2.line(image,(n263[0][17]+range_w,0),(n263[0][17]+range_w,y),(255,0,0),3)\n",
    "\n",
    "                cv2.line(image,(int((n33[0][1]-100)/2),0),(int((n33[0][1]-100)/2),y),(255,0,0),3)\n",
    "                cv2.line(image,(int((x-(n263[0][17]+100))/2+(n263[0][17]+100)),0),(int((x-(n263[0][17]+100))/2+(n263[0][17]+100)),y),(255,0,0),3) # n263[0][17]= n263_x\n",
    "                cv2.line(image,(0,int(y*0.75)),(x,int(y*0.75)),(255,0,0),1) # 책상선\n",
    "#                 cv2.line(image,(0,int(face_landmarks.landmark[10].y*y)),(x,int(face_landmarks.landmark[10].y*y)),(255,0,0),3) # 이마라인선 but, down과 middle의 기준이 애매함, 눈꼬리 기준으로 위아래 나누는게 더 좋을듯\n",
    "                cv2.line(image,(0,eyes_df[eyes_df['idx']==33].y[1]),(x,eyes_df[eyes_df['idx']==33].y[1]),(255,0,0),1) # 오른쪽 바깥 눈꼬리 기준\n",
    "            # put text --------------------------------------------------   \n",
    "                if dir_:\n",
    "                    org=(700,700)\n",
    "                    font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    cv2.putText(image,dir_,org,font,1,(255,0,0),2)\n",
    "                    size, BaseLine=cv2.getTextSize(dir_,font,1,2)\n",
    "                if ear:\n",
    "                    org=(700,600)\n",
    "                    font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    cv2.putText(image,ear,org,font,1,(255,0,0),2)\n",
    "                    size, BaseLine=cv2.getTextSize(ear,font,1,2)\n",
    "\n",
    "#             cv2.imshow('MediaPipe', cv2.flip(image, 0))         # Flip the image horizontally for a selfie-view display.\n",
    "            cv2.imshow('MediaPipe', image)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                ok_flag=0\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(aaaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad7041f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac89fb1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8500a13e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7203e7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdc9703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba56125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1010e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978451d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
