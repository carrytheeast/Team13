{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XBi1CWFKwRo"
      },
      "outputs": [],
      "source": [
        "# google mount"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0jNbl-hv74ZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMmoek8kInl7",
        "outputId": "36da4e44-f93a-4561-e624-24475386b693"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NxholXVvIpn_"
      },
      "outputs": [],
      "source": [
        "# 좀비 런타임 kill\n",
        "# ! ps -ef | grep python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rSzyEp0uItxx"
      },
      "outputs": [],
      "source": [
        "# ! kill 1799 {process_id}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KlyvmLH0AVTY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OyDZz-lL07kK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbLRfPnzAVLe",
        "outputId": "6211670d-d5c2-441e-995b-9510a23ea700"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/yolov7\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/yolov7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rl4zDBTwAVNI",
        "outputId": "07b3020a-11d6-4816-83b9-36fc28ae948b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.8.10.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.9 MB 81.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.2.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (22.1.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.6.0.66)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.21.6)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.17.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.2.2)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<4,>=3.11->mediapipe) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mediapipe) (4.1.1)\n",
            "Installing collected packages: mediapipe\n",
            "Successfully installed mediapipe-0.8.10.1\n"
          ]
        }
      ],
      "source": [
        "pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hSEG7UyPAVPN"
      },
      "outputs": [],
      "source": [
        "# facemesh base import & variables\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import pandas as pd\n",
        "import math\n",
        "import time\n",
        "\n",
        "# path, thres, thres_ear 설정\n",
        "\n",
        "thres = 0.45 # thres < 0.5 (select in 0.40 ~ 0.47)  => e.g. [thres|----|(1-thres)]  \n",
        "thres_ = 1-thres\n",
        "thres_ear = 0.7 # thres_ear >= 0.5 => up\n",
        "pd.set_option('mode.chained_assignment', None)\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "FACEMESH_LEFT_EYE = frozenset([(263, 249), (249, 390), (390, 373), (373, 374),\n",
        "                               (374, 380), (380, 381), (381, 382), (382, 362),\n",
        "                               (263, 466), (466, 388), (388, 387), (387, 386),\n",
        "                               (386, 385), (385, 384), (384, 398), (398, 362)])\n",
        "FACEMESH_RIGHT_EYE = frozenset([(33, 7), (7, 163), (163, 144), (144, 145),\n",
        "                                (145, 153), (153, 154), (154, 155), (155, 133),\n",
        "                                (33, 246), (246, 161), (161, 160), (160, 159),\n",
        "                                (159, 158), (158, 157), (157, 173), (173, 133)])\n",
        "FACEMESH_CONTOURS = frozenset().union(*[FACEMESH_LEFT_EYE, FACEMESH_RIGHT_EYE])\n",
        "FACEMESH_RIGHT_IRIS = frozenset([(469, 470), (470, 471), (471, 472),(472, 469)])\n",
        "FACEMESH_LEFT_IRIS = frozenset([(474, 475), (475, 476), (476, 477),(477, 474)])\n",
        "FACEMESH_IRISES = frozenset().union(*[FACEMESH_LEFT_IRIS, FACEMESH_RIGHT_IRIS])\n",
        "FACEMESH_LEFT_EYE = frozenset([(263, 249), (249, 390), (390, 373), (373, 374),\n",
        "                       (374, 380), (380, 381), (381, 382), (382, 362),\n",
        "                       (263, 466), (466, 388), (388, 387), (387, 386),\n",
        "                       (386, 385), (385, 384), (384, 398), (398, 362)])\n",
        "FACEMESH_RIGHT_EYE = frozenset([(33, 7), (7, 163), (163, 144), (144, 145),\n",
        "                                (145, 153), (153, 154), (154, 155), (155, 133),\n",
        "                                (33, 246), (246, 161), (161, 160), (160, 159),\n",
        "                                (159, 158), (158, 157), (157, 173), (173, 133)])\n",
        "FACEMESH_EYES = frozenset().union(*[FACEMESH_LEFT_EYE, FACEMESH_RIGHT_EYE])\n",
        "right_under = [7,33,133,144,145,153,154,155,163]\n",
        "left_under = [249,263,362,373,374,380,381,382,390]\n",
        "under = frozenset().union(right_under,left_under) # under에는 양끝 눈꺼풀도 포함되어 있음\n",
        "# For webcam input:\n",
        "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
        "\n",
        "# variable\n",
        "ok_flag = 1\n",
        "total_landmarks=[]\n",
        "dir_r = None\n",
        "dir_l = None\n",
        "dir_ = None    \n",
        "aaaa=1\n",
        "time_list = []\n",
        "\n",
        "\n",
        "def distance(x1, y1, x2, y2):\n",
        "    result = math.sqrt( math.pow(x1 - x2, 2) + math.pow(y1 - y2, 2))\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "niO3Y9rlAVQn"
      },
      "outputs": [],
      "source": [
        "# yolov7 base import & variables\n",
        "import argparse\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "from numpy import random\n",
        "import easydict\n",
        "\n",
        "from models.experimental import attempt_load\n",
        "from utils.datasets import LoadStreams, LoadImages\n",
        "from utils.general import check_img_size, check_requirements, check_imshow, non_max_suppression, apply_classifier, \\\n",
        "    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path\n",
        "from utils.plots import plot_one_box\n",
        "from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel\n",
        "from collections import Counter\n",
        "import copy\n",
        "\n",
        "opt = easydict.EasyDict({\n",
        "    \"weights\":'yolov7-e6.pt',\n",
        "    \"source\":'shorts12.mp4',\n",
        "    \n",
        "    \"img_size\":640,\n",
        "    \"conf_thres\":0.25,\n",
        "    \"iou_thres\":0.45,\n",
        "    \"device\":'',\n",
        "    \"view_img\":False,\n",
        "    \"save_txt\":False,\n",
        "    \"save_conf\":False,\n",
        "    \"nosave\":False,\n",
        "    \"classes\":None,\n",
        "    \n",
        "    \"agnostic_nms\":False,\n",
        "    \"augment\":False,\n",
        "    \"updata\":False,\n",
        "    \"project\":'runs/detect',\n",
        "    \"name\":'exp',\n",
        "    \"exist_ok\":False,\n",
        "    \"no_trace\":False,\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5UfcifUeYS1F"
      },
      "outputs": [],
      "source": [
        "# box1 = box1_x1,box1_y1,box1_x2,box1_y2\n",
        "# box2 = xyxy_\n",
        "def IoU(box1, box2): # box1이 그리드, box2가 객체 박스\n",
        "    global box1_x1,box1_y1,box1_x2,box1_y2\n",
        "    # box = (x1, y1, x2, y2)\n",
        "    box1_area = (box1[2] - box1[0] + 1) * (box1[3] - box1[1] + 1)\n",
        "    box2_area = (box2[2] - box2[0] + 1) * (box2[3] - box2[1] + 1)\n",
        "\n",
        "    # obtain x1, y1, x2, y2 of the intersection\n",
        "    x1 = max(box1[0], box2[0])\n",
        "    y1 = max(box1[1], box2[1])\n",
        "    x2 = min(box1[2], box2[2])\n",
        "    y2 = min(box1[3], box2[3])\n",
        "\n",
        "    # compute the width and height of the intersection\n",
        "    w = max(0, x2 - x1 + 1)\n",
        "    h = max(0, y2 - y1 + 1)\n",
        "\n",
        "    inter = w * h\n",
        "    self_iou = inter / box2_area\n",
        "    return self_iou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "a8F_gesWBXKA"
      },
      "outputs": [],
      "source": [
        "def detect():\n",
        "    source, weights, view_img, save_txt, imgsz, trace = opt.source, opt.weights, opt.view_img, opt.save_txt, opt.img_size, not opt.no_trace\n",
        "    save_img = not opt.nosave and not source.endswith('.txt')  # save inference images\n",
        "    webcam = source.isnumeric() or source.endswith('.txt') or source.lower().startswith(\n",
        "        ('rtsp://', 'rtmp://', 'http://', 'https://'))\n",
        "    box1_x1,box1_y1,box1_x2,box1_y2 = 0,0,0,0\n",
        "    top_iou_for10fps = []\n",
        "    iou_list = []\n",
        "    top_iou_obj = None\n",
        "    fps_cnt = 0.0\n",
        "    total_fps_cnt = 0.0\n",
        "    top_iou = None\n",
        "    ear = None\n",
        "    study_obj = ['book','laptop',]\n",
        "    # Initialize\n",
        "    set_logging()\n",
        "    device = select_device(opt.device)\n",
        "    half = device.type != 'cpu'  # half precision only supported on CUDA\n",
        "\n",
        "    # Load model\n",
        "    model = attempt_load(weights, map_location=device)# load FP32 model\n",
        "    stride = int(model.stride.max())  # model stride\n",
        "    imgsz = check_img_size(imgsz, s=stride)  # check img_size\n",
        "\n",
        "    if trace:\n",
        "        model = TracedModel(model, device, opt.img_size)\n",
        "\n",
        "    if half:\n",
        "        model.half()  # to FP16\n",
        "\n",
        "    # Second-stage classifier\n",
        "    classify = False\n",
        "    if classify:\n",
        "        modelc = load_classifier(name='resnet101', n=2)  # initialize\n",
        "        modelc.load_state_dict(torch.load('weights/resnet101.pt', map_location=device)['model']).to(device).eval()\n",
        "\n",
        "    # Set Dataloader\n",
        "    vid_path, vid_writer = None, None\n",
        "    if webcam:\n",
        "        view_img = check_imshow()\n",
        "        cudnn.benchmark = True  # set True to speed up constant image size inference\n",
        "        dataset = LoadStreams(source, img_size=imgsz, stride=stride)\n",
        "    else:\n",
        "        dataset = LoadImages(source, img_size=imgsz, stride=stride)\n",
        "\n",
        "    # Get names and colors\n",
        "    names = model.module.names if hasattr(model, 'module') else model.names\n",
        "    colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n",
        "\n",
        "    # Run inference\n",
        "    if device.type != 'cpu':\n",
        "        model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once\n",
        "    old_img_w = old_img_h = imgsz\n",
        "    old_img_b = 1\n",
        "\n",
        "    t0 = time.time()\n",
        "    first_cnt=0\n",
        "    for path, img, im0s, vid_cap in dataset:\n",
        "        first_cnt+=1\n",
        "        if first_cnt==1:\n",
        "            if vid_cap:\n",
        "                fps = vid_cap.get(cv2.CAP_PROP_FPS)\n",
        "                w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "                h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "            else:  # stream\n",
        "                fps, w, h = 30, im0s.shape[1], im0s.shape[0]\n",
        "            save_path ='run.mp4'    \n",
        "            out = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
        "\n",
        "        \n",
        "        with mp_face_mesh.FaceMesh( max_num_faces=1, refine_landmarks=True,\n",
        "        min_detection_confidence=0.5, min_tracking_confidence=0.5) as face_mesh:\n",
        "            im0s.flags.writeable = False\n",
        "            im0s = cv2.cvtColor(im0s, cv2.COLOR_BGR2RGB)\n",
        "            results = face_mesh.process(im0s)\n",
        "            x = im0s.shape[1] # height\n",
        "            y = im0s.shape[0] # width\n",
        "            book_head = y*1/4 \n",
        "\n",
        "            # Draw the face mesh annotations on the image.\n",
        "            im0s.flags.writeable = True\n",
        "            im0s = cv2.cvtColor(im0s, cv2.COLOR_RGB2BGR)   \n",
        "\n",
        "            if results.multi_face_landmarks:\n",
        "                for face_landmarks in (results.multi_face_landmarks):\n",
        "                    begin = time.time()\n",
        "                    # Drawing base line(facemesh)\n",
        "                    # eyes\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=im0s,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=FACEMESH_CONTOURS,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style())\n",
        "                    # irises\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=im0s,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_IRISES,\n",
        "                        # mp_face_mesh\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_iris_connections_style())\n",
        "                    total_landmarks.append(face_landmarks.landmark)\n",
        "\n",
        "                    # Make DataFrames------------------------------------------------------------\n",
        "                    # iris data frame\n",
        "                    irises=[] # temporary list\n",
        "                    for iris, _ in FACEMESH_IRISES:\n",
        "                        irises.append(iris)\n",
        "                    irises.sort() # order\n",
        "                    total = [] # to be iris dataframe\n",
        "                    for n,_ in enumerate(irises):\n",
        "                        n+=1\n",
        "                        # 좌표 x,y,z값 순서 각 4개씩 (오른쪽눈 < 왼쪽눈) \n",
        "                        if n <=len(FACEMESH_LEFT_IRIS):\n",
        "                            direction = 'right'\n",
        "                        else:\n",
        "                            n-=len(FACEMESH_LEFT_IRIS)\n",
        "                            direction = 'left'\n",
        "                        now = [_,direction ,face_landmarks.landmark[_].x,face_landmarks.landmark[_].y,face_landmarks.landmark[_].z] # info in this time\n",
        "                        total.append(now) \n",
        "                    iris_df = pd.DataFrame(total, columns = ['idx','dir','x','y','z']) # idx: landmark, dir: right/left\n",
        "                    \n",
        "                    # iris / normalized data => resize to origin and to int\n",
        "                    iris_df['x'] = iris_df['x']*x\n",
        "                    iris_df['y'] = iris_df['y']*y\n",
        "                    iris_df['x'] = iris_df['x'].astype('int64')\n",
        "                    iris_df['y'] = iris_df['y'].astype('int64')\n",
        "\n",
        "                    # eyes data frame\n",
        "                    eyes=[] # temporary list\n",
        "                    for eye, _ in FACEMESH_EYES:\n",
        "                        eyes.append(eye)\n",
        "                        eyes.append(_)\n",
        "                    eyes = list(set(eyes))\n",
        "                    eyes.sort() # order\n",
        "                    total = [] # to be eyes dataframe\n",
        "                    for n,_ in enumerate(eyes):\n",
        "                        n+=1\n",
        "                        # 좌표 x,y,z값 순서 각 16개씩 (오른쪽눈 < 왼쪽눈) \n",
        "                        if n <= len(FACEMESH_LEFT_EYE): \n",
        "                            direction = 'right'     \n",
        "                        else:\n",
        "                            n-=int(len(FACEMESH_LEFT_EYE))\n",
        "                            direction = 'left'\n",
        "                        if _ in under:\n",
        "                            loc = 'under'\n",
        "                        else:\n",
        "                            loc = 'up'\n",
        "                        now = [_,direction ,face_landmarks.landmark[_].x,face_landmarks.landmark[_].y,face_landmarks.landmark[_].z,loc] # info in this time\n",
        "                        total.append(now)\n",
        "                    eyes_df = pd.DataFrame(total, columns = ['idx','dir','x','y','z','loc']) # idx: landmark, dir: right/left, loc: up/down\n",
        "                    \n",
        "                    # eyes / normalized data => resize to origin and to int\n",
        "                    eyes_df['x'] = eyes_df['x']*x\n",
        "                    eyes_df['y'] = eyes_df['y']*y\n",
        "                    eyes_df['x'] = eyes_df['x'].astype('int64')\n",
        "                    eyes_df['y'] = eyes_df['y'].astype('int64')\n",
        "                    \n",
        "                    # Gaze Point Estimation------------------------------------------------------------\n",
        "                    \n",
        "                    \n",
        "                    # 오른쪽 동공의 각 끝 좌표\n",
        "                    n469_x, n469_y = iris_df[iris_df['idx']==469].x,iris_df[iris_df['idx']==469].y\n",
        "                    n471_x, n471_y = iris_df[iris_df['idx']==471].x,iris_df[iris_df['idx']==471].y\n",
        "                    # 왼쪽 동공의 각 끝 좌표\n",
        "                    n474_x, n474_y = iris_df[iris_df['idx']==474].x,iris_df[iris_df['idx']==474].y\n",
        "                    n476_x, n476_y = iris_df[iris_df['idx']==476].x,iris_df[iris_df['idx']==476].y\n",
        "                    \n",
        "                    # 오른쪽 동공의 중심좌표\n",
        "                    dot_r = ((int(n469_x) + int(n471_x)) / 2, (int(n469_y) + int(n471_y)) / 2)\n",
        "                    # 왼쪽 동공의 중심좌표\n",
        "                    dot_l = ((int(n474_x) + int(n476_x)) / 2, (int(n474_y) + int(n476_y)) / 2)\n",
        "\n",
        "                    # 오른쪽 눈꺼풀의 각 끝 좌표와 길이\n",
        "                    n33 = (eyes_df[eyes_df['idx']==33].x,eyes_df[eyes_df['idx']==33].y)\n",
        "                    n133 = (eyes_df[eyes_df['idx']==133].x,eyes_df[eyes_df['idx']==133].y) \n",
        "                    # dist_r = math.dist(n33,n133)\n",
        "                    dist_r = distance(eyes_df[eyes_df['idx']==33].iloc[0].x,eyes_df[eyes_df['idx']==33].iloc[0].y,eyes_df[eyes_df['idx']==133].iloc[0].x,eyes_df[eyes_df['idx']==133].iloc[0].y)\n",
        "                    \n",
        "                    # 왼쪽 눈꺼풀의 각 끝 좌표와 길이\n",
        "                    n263 = (eyes_df[eyes_df['idx']==263].x,eyes_df[eyes_df['idx']==263].y)\n",
        "                    n362 = (eyes_df[eyes_df['idx']==362].x,eyes_df[eyes_df['idx']==362].y)\n",
        "                    # dist_l = math.dist(n263,n362)\n",
        "                    dist_l = distance(eyes_df[eyes_df['idx']==263].iloc[0].x,eyes_df[eyes_df['idx']==263].iloc[0].y,eyes_df[eyes_df['idx']==362].iloc[0].x,eyes_df[eyes_df['idx']==362].iloc[0].y)\n",
        "\n",
        "\n",
        "                    # 오른쪽 밑 눈꺼풀\n",
        "                    n145 = (eyes_df[eyes_df['idx']==145].x,eyes_df[eyes_df['idx']==145].y)\n",
        "                    # 왼쪽 밑 눈꺼풀\n",
        "                    n374 = (eyes_df[eyes_df['idx']==374].x,eyes_df[eyes_df['idx']==374].y)\n",
        "                    \n",
        "                    # gaze point line val\n",
        "                    # 눈 좌표 값 방향기준\n",
        "                    \n",
        "                    range_w = int(x*.07) # 좌측부터 2,3번째 그리드의 x좌표 간격에 각각 +,- 값 \n",
        "\n",
        "                    # gaze_point_line --------------------------------------------------\n",
        "                    right_line_x = ((n33[0][1]-range_w)/2)/2\n",
        "                    rightcenter_line_x = ((n33[0][1]-range_w)/2) + ((n33[0][1]-range_w)/2)/2\n",
        "                    center_line_x = (n263[0][17]+range_w - (n33[0][1]-range_w))/2 + (n33[0][1]-range_w)\n",
        "                    leftcenter_line_x = (n263[0][17]+range_w)+(x-(n263[0][17]+range_w))/4\n",
        "                    left_line_x = (n263[0][17]+range_w) + (x-(n263[0][17]+range_w))*3/4\n",
        "                    \n",
        "                    up_line_y = eyes_df[eyes_df['idx']==33].y[1]/2\n",
        "                    middle_line_y = eyes_df[eyes_df['idx']==33].y[1] + (y*.75 -  eyes_df[eyes_df['idx']==33].y[1])/2\n",
        "                    down_line_y = y*.75+y*.125\n",
        "                    \n",
        "                    # 오른쪽 눈 방향 (좌우)\n",
        "                    # r_ratio = round((math.dist(dot_r, n133)/dist_r),5) # if ratio < thres: left\n",
        "                    r_ratio = round(distance((int(n469_x)+int(n471_x))/2,(int(n469_y)+int(n471_y))/2,eyes_df[eyes_df['idx']==133].iloc[0].x,eyes_df[eyes_df['idx']==133].iloc[0].y)/dist_r,5)\n",
        "                    if r_ratio:\n",
        "                        if r_ratio < thres:\n",
        "                            dir_r = 'Right'\n",
        "                        elif r_ratio > thres_:\n",
        "                            dir_r = 'Left'\n",
        "                        else:\n",
        "                            dir_r = 'Center'\n",
        "                    # 왼쪽 눈 방향 (좌우)\n",
        "                    # l_ratio = round((math.dist(dot_l, n263)/dist_l),5) # if ratio < thres: left                \n",
        "                    l_ratio = round(distance((int(n474_x) + int(n476_x)) / 2, (int(n474_y) + int(n476_y)) / 2,eyes_df[eyes_df['idx']==263].iloc[0].x,eyes_df[eyes_df['idx']==263].iloc[0].y)/dist_l,5)\n",
        "                    if l_ratio:\n",
        "                        if l_ratio < thres:\n",
        "                            dir_l = 'Right'\n",
        "                        elif l_ratio > thres_:\n",
        "                            dir_l = 'Left'\n",
        "                        else:\n",
        "                            dir_l = 'Center'\n",
        "\n",
        "                    # 통합 눈 방향 (좌우)\n",
        "                    if dir_r == dir_l:\n",
        "                        dir_ = dir_r\n",
        "                        if dir_r == 'Right':\n",
        "                            gaze_line_x = left_line_x\n",
        "                            box1_x1, box1_x2 = int((x-(n263[0][17]+range_w))/2+(n263[0][17]+range_w)), x\n",
        "                        else:\n",
        "                            gaze_line_x = right_line_x\n",
        "                            box1_x1, box1_x2 = 0, int((n33[0][1]-range_w)/2)\n",
        "\n",
        "                    elif ((dir_r =='Right') and (dir_l =='Left')) or ((dir_r == 'Left') and (dir_l == 'Right')):\n",
        "                        dir_ = 'Center' # 양 끝 값일 때, 중앙으로\n",
        "                        gaze_line_x = center_line_x\n",
        "                        box1_x1, box1_x2 = n33[0][1]-range_w, n263[0][17]+range_w\n",
        "                    else: # [rightcenter, leftcenter, centerright, centerleft]\n",
        "                        dir_ = [dir_r,dir_l]\n",
        "                        if ('Right' in dir_) and ('Center' in dir_):\n",
        "                            dir_ = 'RightCenter'\n",
        "                            gaze_line_x = leftcenter_line_x\n",
        "                            box1_x1, box1_x2 = n263[0][17]+range_w,int((x-(n263[0][17]+range_w))/2+(n263[0][17]+range_w))\n",
        "                        if ('Left' in dir_) and ('Center' in dir_):\n",
        "                            dir_ = 'LeftCenter'\n",
        "                            gaze_line_x = rightcenter_line_x\n",
        "                            box1_x1, box1_x2 = int((n33[0][1]-range_w)/2),n33[0][1]-range_w\n",
        "            #                 up_r = iris_df[iris_df['idx']==472]['y'][3] - eyes_df[eyes_df['idx']==145].y[4] # if up<0: up\n",
        "            #                 up_l = iris_df[iris_df['idx']==477]['y'][7] - eyes_df[eyes_df['idx']==374].y[20] # if up<0: up\n",
        "\n",
        "                    # EAR ratio--------------------------------------------------\n",
        "                    # 오른쪽 눈 방향 (상하) : (|161-163|+|157-154|)/2*|133-33|*1/100\n",
        "                    n161 = (eyes_df[eyes_df['idx']==161].x,eyes_df[eyes_df['idx']==161].y)\n",
        "                    n163 = (eyes_df[eyes_df['idx']==163].x,eyes_df[eyes_df['idx']==163].y)\n",
        "                    n154 = (eyes_df[eyes_df['idx']==154].x,eyes_df[eyes_df['idx']==154].y)\n",
        "                    n157 = (eyes_df[eyes_df['idx']==157].x,eyes_df[eyes_df['idx']==157].y)\n",
        "                    # right_ear = (abs(math.dist(n161,n163))+abs(math.dist(n157,n154)))/2*abs(math.dist(n133,n33))/1000\n",
        "                    right_ear = (abs(distance(eyes_df[eyes_df['idx']==161].iloc[0].x,eyes_df[eyes_df['idx']==161].iloc[0].y,eyes_df[eyes_df['idx']==163].iloc[0].x,eyes_df[eyes_df['idx']==163].iloc[0].y))+\\\n",
        "                                  abs(distance(eyes_df[eyes_df['idx']==157].iloc[0].x,eyes_df[eyes_df['idx']==157].iloc[0].y,eyes_df[eyes_df['idx']==154].iloc[0].x,eyes_df[eyes_df['idx']==154].iloc[0].y)))/2*\\\n",
        "                                  abs(distance(eyes_df[eyes_df['idx']==133].iloc[0].x,eyes_df[eyes_df['idx']==133].iloc[0].y,eyes_df[eyes_df['idx']==33].iloc[0].x,eyes_df[eyes_df['idx']==33].iloc[0].y))/1000\n",
        "                    # 왼쪽 눈 방향 (상하) : (|384-381|+|388-390|)/2*|263-362|*1/100\n",
        "                    n381 = (eyes_df[eyes_df['idx']==381].x,eyes_df[eyes_df['idx']==381].y)\n",
        "                    n384 = (eyes_df[eyes_df['idx']==384].x,eyes_df[eyes_df['idx']==384].y)\n",
        "                    n388 = (eyes_df[eyes_df['idx']==388].x,eyes_df[eyes_df['idx']==388].y)\n",
        "                    n390 = (eyes_df[eyes_df['idx']==390].x,eyes_df[eyes_df['idx']==390].y)\n",
        "                    # left_ear = (abs(math.dist(n384,n381))+abs(math.dist(n388,n390)))/2*abs(math.dist(n263,n362))/1000\n",
        "                    left_ear = (abs(distance(eyes_df[eyes_df['idx']==381].iloc[0].x,eyes_df[eyes_df['idx']==381].iloc[0].y,eyes_df[eyes_df['idx']==384].iloc[0].x,eyes_df[eyes_df['idx']==384].iloc[0].y))+\\\n",
        "                                abs(distance(eyes_df[eyes_df['idx']==388].iloc[0].x,eyes_df[eyes_df['idx']==388].iloc[0].y,eyes_df[eyes_df['idx']==390].iloc[0].x,eyes_df[eyes_df['idx']==390].iloc[0].y)))/2*\\\n",
        "                                abs(distance(eyes_df[eyes_df['idx']==263].iloc[0].x,eyes_df[eyes_df['idx']==263].iloc[0].y,eyes_df[eyes_df['idx']==362].iloc[0].x,eyes_df[eyes_df['idx']==362].iloc[0].y))/1000\n",
        "                    # Right iris(468) z vs Left iris(473) z: higher value is closer camera.\n",
        "                    if face_landmarks.landmark[468].z > face_landmarks.landmark[473].z:\n",
        "                        using_ear = right_ear\n",
        "                    else:\n",
        "                        using_ear = left_ear\n",
        "\n",
        "                    if using_ear <= 0.15:\n",
        "                        ear = 'CLOSE'\n",
        "                        box1_y1, box1_y2 = int(y*0.75), y # down과 같음\n",
        "                        gaze_line_y = down_line_y\n",
        "                    elif (using_ear > 0.15) and (using_ear <= thres_ear/2):# thres_ear_ = thres_ear/2\n",
        "                        ear = 'DOWN'\n",
        "                        gaze_line_y = down_line_y\n",
        "                        box1_y1, box1_y2 = int(y*0.75), y\n",
        "                    elif (using_ear > 0.4) and (using_ear < thres_ear): # thres_ear = 0.7\n",
        "                        ear = 'MIDDLE'\n",
        "                        gaze_line_y = middle_line_y\n",
        "                        box1_y1, box1_y2 = eyes_df[eyes_df['idx']==33].y[1], int(y*0.75)\n",
        "                    else:\n",
        "                        ear = 'UP'\n",
        "                        gaze_line_y = up_line_y\n",
        "                        box1_y1, box1_y2 = 0,eyes_df[eyes_df['idx']==33].y[1]\n",
        "                        \n",
        "                img = torch.from_numpy(img).to(device)\n",
        "                img = img.half() if half else img.float()  # uint8 to fp16/32\n",
        "                img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
        "                if img.ndimension() == 3:\n",
        "                    img = img.unsqueeze(0)\n",
        "\n",
        "                # Warmup\n",
        "                if device.type != 'cpu' and (old_img_b != img.shape[0] or old_img_h != img.shape[2] or old_img_w != img.shape[3]):\n",
        "                    old_img_b = img.shape[0]\n",
        "                    old_img_h = img.shape[2]\n",
        "                    old_img_w = img.shape[3]\n",
        "                    for i in range(3):\n",
        "                        model(img, augment=opt.augment)[0]\n",
        "\n",
        "                # Inference\n",
        "                t1 = time_synchronized()\n",
        "                pred = model(img, augment=opt.augment)[0]\n",
        "                t2 = time_synchronized()\n",
        "\n",
        "                # Apply NMS\n",
        "                pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres, classes=opt.classes, agnostic=opt.agnostic_nms)\n",
        "                t3 = time_synchronized()\n",
        "\n",
        "                # Apply Classifier\n",
        "                if classify:\n",
        "                    pred = apply_classifier(pred, modelc, img, im0s)\n",
        "                \n",
        "                if results.multi_face_landmarks:\n",
        "\n",
        "                    # Grid line--------------------------------------------------\n",
        "                    # out.write(im0s)\n",
        "                    # right 옆 - 왼쪽에서부터 2\n",
        "                    cv2.line(im0s,(n33[0][1]-range_w,0),(n33[0][1]-range_w,y),(255,0,0),1) # n33[0][1]= n33_x, range_w = 50\n",
        "                    # left 옆 - 3\n",
        "                    cv2.line(im0s,(n263[0][17]+range_w,0),(n263[0][17]+range_w,y),(255,0,0),1)\n",
        "\n",
        "                    # right center - 1 \n",
        "                    cv2.line(im0s,(int((n33[0][1]-range_w)/2),0),(int((n33[0][1]-range_w)/2),y),(255,0,0),1)\n",
        "                    # left center - 4\n",
        "                    cv2.line(im0s,(int((x-(n263[0][17]+range_w))/2+(n263[0][17]+range_w)),0),(int((x-(n263[0][17]+range_w))/2+(n263[0][17]+range_w)),y),(255,0,0),1) # n263[0][17]= n263_x\n",
        "                    \n",
        "                    # table\n",
        "                    cv2.line(im0s,(0,int(y*0.75)),(x,int(y*0.75)),(255,0,0),1)\n",
        "                    # eye_line \n",
        "                    cv2.line(im0s,(0,eyes_df[eyes_df['idx']==33].y[1]),(x,eyes_df[eyes_df['idx']==33].y[1]),(255,0,0),1) \n",
        "                    #cv2.line(im0s,(0,int(face_landmarks.landmark[10].y*y)),(x,int(face_landmarks.landmark[10].y*y)),(255,0,0),3) # 이마라인선 but, down과 middle의 기준이 애매함, 눈꼬리 기준으로 위아래 나누는게 더 좋을듯\n",
        "                    \n",
        "                    # gaze point line --------------------------------------------------\n",
        "                            # print(gaze_line_x)\n",
        "                            # print(gaze_line_y)\n",
        "\n",
        "\n",
        "                    # put text --------------------------------------------------   \n",
        "                    if dir_:\n",
        "                        org=(int(x*0.3),int(y*0.3))\n",
        "                        font=cv2.FONT_HERSHEY_SIMPLEX\n",
        "                        cv2.putText(im0s,dir_,org,font,.5,(255,0,0),1)\n",
        "                        # size, BaseLine=cv2.getTextSize(dir_,font,1,2)\n",
        "                    if ear:\n",
        "                        org=(int(x*0.3),int(y*0.4))\n",
        "                        font=cv2.FONT_HERSHEY_SIMPLEX\n",
        "                        cv2.putText(im0s,ear,org,font,.5,(255,0,0),1)\n",
        "                        # size, BaseLine=cv2.getTextSize(ear,font,1,2)\n",
        "                iou_key = []\n",
        "                iou_val = []\n",
        "                # Process detections\n",
        "                for i, det in enumerate(pred):  # detections per image\n",
        "                    \n",
        "                    if webcam:  # batch_size >= 1\n",
        "                        p, s, frame = path[i], '%g: ' % i, dataset.count\n",
        "                    else:\n",
        "                        p, s, frame = path, '', getattr(dataset, 'frame', 0)\n",
        "\n",
        "                    # gn = torch.tensor(im0s.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
        "                    if len(det):\n",
        "                        # Rescale boxes from img_size to im0 size\n",
        "                        det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0s.shape).round()\n",
        "\n",
        "                        # Print results   \n",
        "                        for c in det[:, -1].unique():\n",
        "                            n = (det[:, -1] == c).sum()  # detections per class\n",
        "                            s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
        "                        \n",
        "    # --------------------------------------------------------------------------------------------------------- 1 frame 내의 bbox 모두\n",
        "                        iou_key = []\n",
        "                        iou_val = []\n",
        "                        iou_xyxy = []\n",
        "                        cell_phone_xyxy = 0\n",
        "                        for  *xyxy, conf, cls in reversed(det):\n",
        "                          \n",
        "                          xyxy_ = []\n",
        "                          for _ in xyxy:\n",
        "                              xyxy_.append(_.item())\n",
        "                          # print(xyxy_)\n",
        "\n",
        "                          # 사용물품이 화면 중앙에서 사용 될 때, 탐지 X 보완(ex. cell phone)\n",
        "                          if names[int(cls.item())] =='book':\n",
        "                              book_head = xyxy_[1] # 공부X 물품 기준선\n",
        "\n",
        "                          if (names[int(cls.item())] =='cell phone') and (xyxy_[1] < book_head):\n",
        "                              cell_phone_xyxy = xyxy # 휴대폰의 위치\n",
        "\n",
        "                          # print(\"cls:\",names[int(cls.item())])\n",
        "                          label = f'{names[int(cls)]} {conf:.2f}'\n",
        "                          # 객체별 bbox 그리기\n",
        "                          plot_one_box(xyxy, im0s, label=label, color=colors[int(cls)], line_thickness=1)\n",
        "\n",
        "                          # iou\n",
        "                          if box1_x1 or box1_y1 or box1_x2 or box1_y2:\n",
        "                              box1 = [box1_x1, box1_y1, box1_x2, box1_y2]\n",
        "                              box2 = xyxy_\n",
        "                              iou = IoU(box1,box2)\n",
        "                              iou_key.append(names[int(cls.item())])\n",
        "                              iou_val.append(iou)\n",
        "                              iou_xyxy.append(xyxy_)\n",
        "                          \n",
        "                          # 들여쓰기 주의\n",
        "                        if iou_key or iou_val:\n",
        "                            top_iou = iou_key[np.argmax(iou_val)] # 1 frame의 가장 높은 값 명사로 저장됨(그리드 기준)\n",
        "                            \n",
        "                            if cell_phone_xyxy: # 예외 정보(사용물품 화면중앙에서 사용 될 때의 보완점)\n",
        "                                top_iou = 'cell phone'\n",
        "                            \n",
        "                            top_iou_for10fps.append(top_iou)\n",
        "\n",
        "                        if top_iou: # 현재 보는 거\n",
        "                            org=(int(x*0.1),int(y*0.1))\n",
        "                            font=cv2.FONT_HERSHEY_SIMPLEX\n",
        "                            cv2.putText(im0s,'NOW: '+top_iou, org, font,.5,(255,0,0),1)\n",
        "\n",
        "                        # writing => top_iou_obj(10fps동안 빈도수 1등)\n",
        "                        if top_iou_obj: \n",
        "                            org=(int(x*0.1),int(y*0.2))\n",
        "                            font=cv2.FONT_HERSHEY_SIMPLEX\n",
        "                            cv2.putText(im0s,top_iou_obj+' in 10FPS',org,font,.5,(255,0,0),1)    \n",
        "\n",
        "                        # 10개의 프레임 중에 가장 높은 사물\n",
        "                        if top_iou_for10fps:\n",
        "                            counter_top_iou = Counter(top_iou_for10fps)\n",
        "                            top_iou_obj = list(counter_top_iou.keys())[(np.argmax(list(counter_top_iou.values())))] # 명사로 저장됨\n",
        "                            # print('top_iou_for10fps :',top_iou_for10fps)\n",
        "                            # print('top_iou_obj:',top_iou_obj)\n",
        "                        # 최근 10개의 프레임\n",
        "                        if len(top_iou_for10fps) == 10: \n",
        "                            top_iou_for10fps = top_iou_for10fps[1:]                      \n",
        "                        \n",
        "                        if top_iou_obj in study_obj: \n",
        "                            fps_cnt += 1/30 # 순공시간, 1단위: 1초\n",
        "                            # print('{}m {}s {}ms'.format(fps_cnt//60,fps_cnt//1, fps_cnt%1))                \n",
        "\n",
        "                        if fps_cnt: # 현재 시간\n",
        "                            org=(int(x*0.2),int(y*0.1))\n",
        "                            font=cv2.FONT_HERSHEY_SIMPLEX\n",
        "                            cv2.putText(im0s,'now: {}:{}:{:.3f}'.format(int(fps_cnt//60),int(fps_cnt//1),fps_cnt%1), org, font,.5,(255,0,0),1)              \n",
        "                                  \n",
        "                        total_fps_cnt += 1/30 # 전체시간\n",
        "                        if total_fps_cnt: # 전체시간\n",
        "                            org=(int(x*0.4),int(y*0.1))\n",
        "                            font=cv2.FONT_HERSHEY_SIMPLEX\n",
        "                            cv2.putText(im0s,'total: {}:{}:{:.3f}'.format(int(total_fps_cnt//60),int(total_fps_cnt//1),total_fps_cnt%1), org, font,.5,(255,0,0),1)                    \n",
        "                    \n",
        "    # gaze point line\n",
        "                        if ear != 'UP':\n",
        "                          # if (xyxy_[1] < book_head) and (names[int(cls.item())] =='cell phone'):\n",
        "                          # if (iou_xyxy[np.argmax(iou_val)][1] < book_head):\n",
        "                          if cell_phone_xyxy:\n",
        "                            if top_iou_obj =='cell phone':\n",
        "                              cv2.line(im0s,(int(face_landmarks.landmark[468].x * x),int(face_landmarks.landmark[468].y * y)),\n",
        "                                      (int((cell_phone_xyxy[0] + cell_phone_xyxy[2]) / 2 - x * .02),int((cell_phone_xyxy[1] + cell_phone_xyxy[3]) / 2))\n",
        "                                      ,(255,0,0),2)\n",
        "                              cv2.line(im0s,(int(face_landmarks.landmark[473].x * x),int(face_landmarks.landmark[473].y * y)),\n",
        "                                      (int((cell_phone_xyxy[0] + cell_phone_xyxy[2]) / 2 + x * .02),int((cell_phone_xyxy[1] + cell_phone_xyxy[3]) / 2))\n",
        "                                      ,(255,0,0),2)                                                \n",
        "                              \n",
        "                            out.write(im0s)\n",
        "                            # cv2_imshow(im0s)  \n",
        "\n",
        "                          else:\n",
        "                            cv2.line(im0s,(int(face_landmarks.landmark[468].x*x),int(face_landmarks.landmark[468].y*y)),(int(gaze_line_x-x*.07), int(gaze_line_y)),(255,0,0),2) \n",
        "                            cv2.line(im0s,(int(face_landmarks.landmark[473].x*x),int(face_landmarks.landmark[473].y*y)),(int(gaze_line_x+x*.07), int(gaze_line_y)),(255,0,0),2)\n",
        "                            \n",
        "                            out.write(im0s)\n",
        "                            # cv2_imshow(im0s)\n",
        "                        else:\n",
        "                          # cv2_imshow(im0s)                      \n",
        "                          out.write(im0s)\n",
        "    # --------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "                    # Print time (inference + NMS)\n",
        "                    print(f'{s}Done. ({(1E3 * (t2 - t1)):.1f}ms) Inference, ({(1E3 * (t3 - t2)):.1f}ms) NMS')\n",
        "            else: # facemesh 안될 때\n",
        "                total_fps_cnt += 1/30\n",
        "                if total_fps_cnt:\n",
        "                    org=(int(x*0.4),int(y*0.1))\n",
        "                    font=cv2.FONT_HERSHEY_SIMPLEX\n",
        "                    cv2.putText(im0s,'total: {}:{}:{:.3f}'.format(int(total_fps_cnt//60),int(total_fps_cnt//1),total_fps_cnt%1), org, font,.5,(255,0,0),1)                    \n",
        "                # cv2_imshow(im0s)\n",
        "                out.write(im0s)\n",
        "                                \n",
        "    vid_cap.release()\n",
        "    out.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "5jqEBRExov6W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d77b0d58-deb2-43d0-8671-53b7ece7c66c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "15//7"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "O0_02xCmdOBu"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "OXicWqv_ov_g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f51d27aa-6ba0-4097-f593-9af22f430616"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'b', 'a']\n"
          ]
        }
      ],
      "source": [
        "a = ['a','b','a']\n",
        "if a[0]:\n",
        "  print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "9tWl9XlUnRLQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62H8_fHmL1mO",
        "outputId": "7e9a3b2a-cdfb-4e76-efbd-4e12afa25059"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "video 1/1 (1/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.8ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (2/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 cell phone, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (3/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 cell phone, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (4/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 cell phone, Done. (17.9ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (5/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 cell phone, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (6/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (7/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (8/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (9/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 cell phone, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (10/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (11/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 cell phone, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (12/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (13/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (14/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 scissors, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (15/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 scissors, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (16/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 scissors, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (17/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 scissors, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (18/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.7ms) NMS\n",
            "video 1/1 (19/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 fork, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (20/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (21/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 cell phone, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (22/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 cell phone, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (23/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 fork, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (24/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (25/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (26/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (27/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (28/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.0ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (29/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (30/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 scissors, Done. (17.9ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (31/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (32/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (33/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.0ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (34/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (35/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (36/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (37/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 fork, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (38/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.0ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (39/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (40/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (41/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (42/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (43/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (44/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (45/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (46/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (47/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (48/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (49/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (50/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 cell phone, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (51/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (52/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (53/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (54/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (3.1ms) NMS\n",
            "video 1/1 (55/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (56/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (57/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (58/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (59/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (60/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (61/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (62/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (63/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (64/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (65/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (66/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.0ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (67/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (68/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (69/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (70/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (71/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (72/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.0ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (73/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (74/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.0ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (75/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (76/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (77/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (78/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (19.1ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (79/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (80/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.1ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (81/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (82/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.0ms) Inference, (1.6ms) NMS\n",
            "video 1/1 (83/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (84/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (85/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.6ms) Inference, (1.4ms) NMS\n",
            "video 1/1 (86/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (87/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.0ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (88/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (89/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (90/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (91/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (92/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.0ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (93/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (94/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (95/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (96/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (2.1ms) NMS\n",
            "video 1/1 (97/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (98/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (99/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (100/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (18.0ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (101/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (102/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (103/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (104/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (105/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (106/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (107/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (108/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (109/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (110/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (111/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (112/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (113/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (114/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (115/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (116/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (117/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (118/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (119/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (120/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (121/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (122/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (123/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (124/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 toothbrush, Done. (17.9ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (125/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (126/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 cell phone, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (127/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (128/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (129/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (130/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 remote, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (131/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (132/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (133/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (134/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (18.0ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (135/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (136/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 toothbrush, Done. (18.0ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (137/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (138/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 toothbrush, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (139/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (140/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 toothbrush, Done. (18.0ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (141/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 toothbrush, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (142/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 toothbrush, Done. (18.0ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (143/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 toothbrush, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (144/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 toothbrush, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (145/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 toothbrush, Done. (18.0ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (146/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (147/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 toothbrush, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (148/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 toothbrush, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (149/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 toothbrush, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (150/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 toothbrush, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (151/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 toothbrush, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (152/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 toothbrush, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (153/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 toothbrush, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (154/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 toothbrush, Done. (18.0ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (155/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 toothbrush, Done. (18.0ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (156/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 toothbrush, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (157/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 toothbrush, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (158/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (159/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (160/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (161/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (162/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (163/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (164/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (165/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 toothbrush, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (166/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (167/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 toothbrush, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (168/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (169/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (170/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (171/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (172/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (173/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (174/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.0ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (175/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (176/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (177/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (178/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (179/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (180/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (181/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (182/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (183/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (184/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.1ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (185/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (186/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (187/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (188/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (189/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (190/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (191/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (192/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (193/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (194/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (195/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (196/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (197/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (198/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (199/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (200/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (201/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (202/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (203/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (204/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (205/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (206/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (207/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (208/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (209/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (210/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.0ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (211/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (212/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (213/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (214/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (215/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (216/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.0ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (217/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (218/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (219/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (220/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (221/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (222/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.0ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (223/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (224/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (225/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (226/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (227/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (228/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (229/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (230/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (231/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (232/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (233/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (234/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (235/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (236/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.0ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (237/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (238/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (239/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (240/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (241/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (242/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (243/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (244/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.0ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (245/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (246/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (247/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (248/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (249/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (250/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (251/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (252/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (253/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (254/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (255/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (256/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (257/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.8ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (258/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (259/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (260/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (261/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (262/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (263/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (264/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (265/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (266/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (267/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (268/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (269/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (270/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (271/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (272/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (273/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (274/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (275/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (276/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (277/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (278/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (279/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (280/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (281/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (282/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (283/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (284/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (285/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (286/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (287/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (288/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 handbag, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (289/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 handbag, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (290/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (291/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (292/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (293/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (294/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (295/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (296/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.0ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (297/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (298/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (299/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (300/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (301/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (302/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (303/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (304/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (305/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (306/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (307/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (308/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (309/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (310/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (311/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (312/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.0ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (313/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (314/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (315/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (316/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (317/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (318/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.0ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (319/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (320/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (321/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (322/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (323/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (324/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (325/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.0ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (326/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.0ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (327/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (328/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (329/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.0ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (330/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (331/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (332/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (333/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (334/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (335/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (336/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.0ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (337/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (338/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (339/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (340/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (341/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (342/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (343/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (344/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (345/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (346/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (347/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (348/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (349/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (350/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (351/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (352/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (353/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (354/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (355/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (356/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (357/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (358/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (359/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (360/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (361/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (362/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (363/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (364/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (365/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (366/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (367/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (368/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (369/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (27.4ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (370/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (371/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (372/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (373/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (3.0ms) NMS\n",
            "video 1/1 (374/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (375/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.0ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (376/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (377/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (378/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.8ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (379/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.0ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (380/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.3ms) NMS\n",
            "video 1/1 (381/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (382/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (383/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (384/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (385/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (386/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (387/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (388/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (389/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (390/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (391/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.0ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (392/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (393/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (394/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 knife, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (395/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 cell phone, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (396/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 fork, 1 refrigerator, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (397/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (398/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 donut, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (399/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (400/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (401/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (402/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.8ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (403/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (404/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (405/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (406/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.8ms) NMS\n",
            "video 1/1 (407/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.0ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (408/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (409/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (410/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (411/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (412/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (413/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (18.0ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (414/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (415/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (416/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "video 1/1 (417/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, 1 refrigerator, Done. (17.9ms) Inference, (1.2ms) NMS\n",
            "video 1/1 (418/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.0ms) NMS\n",
            "video 1/1 (419/419) /content/drive/MyDrive/yolov7/shorts12.mp4: 1 person, Done. (17.9ms) Inference, (1.1ms) NMS\n",
            "Optimizer stripped from yolov7.pt, 75.6MB\n"
          ]
        }
      ],
      "source": [
        "# 실행문\n",
        "with torch.no_grad():\n",
        "    if opt.update:  # update all models (to fix SourceChangeWarning)\n",
        "        for opt.weights in ['yolov7.pt']:\n",
        "            detect()\n",
        "            strip_optimizer(opt.weights)\n",
        "    else:\n",
        "        detect()  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sp_SpoS-58mp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cdf6c82-575c-468c-cd19-90357ced0655"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "(32 * 1/30)//1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hr74pQGvAVUx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0379c029-1051-43c6-f3a8-cb947b0ce54a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "720"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "24*30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npgacp6kAVWS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xcjmy0IQAVX5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5260trbiAVau"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "yolov7+facemesh__.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}